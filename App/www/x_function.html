<p><strong>Overview.</strong> In this tab we provide in-depth explanation of the X-functions specifically tailored for financial time series that the research team developed. The methodology was first proposed in a paper by Wildi and Hadji Misheva (2022) which is made available at the following link: <a href="https://www.explainableaiforfinance.com/repository-of-papers">https://www.explainableaiforfinance.com/repository-of-papers</a></p>
<p><strong>Description of Methodology.</strong> In order to preserve data-integrity as well as model-integrity we propose to analyze the effect of infinitesimal changes of the explanatory variables on some function of the net-output at each time-point t = 1, ..., T.</p>
<p>Specifically, we start from the simplest case in which the X-function is the identity, so the X-function of the output is the output, and we calculate the derivative, $w_{it}:=\partial o<em>t/\partial x</em>{it}$, $i=1,...,m$, for each explanatory variable $x_{it}$ as a function of time. This in turn gives us the sensitivities of the outputs for each explanatory variable in the net over time, t = 1, ..., T.</p>
<p>In order to complete the ’explanation’ derived from the identity $ef(\cdot)=Id$, one can add a synthetic intercept to each output neuron <img src="file:///C:/Users/Admin/AppData/Local/Temp/msohtmlclip1/01/clip_image002.png" alt=""> defined according to:</p>
<p>$$
\begin{eqnarray}\label{intercept}</p>
<p>b_t:=o<em>t-\sum</em>{i=1}^m w<em>{it}x</em>{it}</p>
<p>\end{eqnarray}
$$</p>
<p>For each output neuron <img src="file:///C:/Users/Admin/AppData/Local/Temp/msohtmlclip1/01/clip_image002.png" alt="">,  the resulting derivatives or ’explanations’ $b<em>t,w</em>{1t},...,w_{mt}$  generate a new data-flow which is referred to as <strong>Linear Parameter Data (LPDs)</strong>. The LPD is a matrix of dimension T ∗ (n + 1), irrespective of the complexity of the neural net, with t−th row denoted by<img src="file:///C:/Users/Admin/AppData/Local/Temp/msohtmlclip1/01/clip_image006.png" alt="">$LPD_t:=(b<em>t,w</em>{1t},...,w_{mt})$.</p>
<p><strong>Intuition:</strong> The LPD can be interpreted in terms of <strong>exact replication of the net by a linear model at each time point t</strong> and the natural time-ordering of LPDs subsequently allows to examine changes of the linear replication as a function of time.</p>
<p>With the algorithm developed, for each output neuron, we obtain the derivatives (which in turn are the new data-flow we call LPDs). In order to give an intuition as to the sensitivities/explanations we want to obtain let&#39;s imagine the following brute approach:</p>
<ul>
<li>We start by training a neural network (NN) on the specified inputs and response and store the results </li>
<li>Next, we perturb a selected input slightly</li>
<li>We use the trained NN and make the predictions for the changed inputs</li>
<li>For each changed variable, we collect the perturbed data and the corresponding NN-output and we fit a linear model and obtain the weights.</li>
<li>We train the net for 100 different random initialization and <strong>we observe the dependency of the LPDs across the different random nets.</strong></li>
</ul>
<p>By using the derivatives approach, <strong>we are in turn obtaining the exact sensitivities of the outputs</strong> for each explanatory variable in the net over time, without recomputing perturbated outputs based on perturbated inputs and without refitting.</p>
