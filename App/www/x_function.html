<p>In this project, we developed simple x-functions that allow the user to have meaningful insights as to the outputs of complex neural network models,  that are time specific.</p>
<p>We propose a family of Explainability (X-)functions xf(.) for assigning meaning to the netâ€™s response or output ğ‘œ<em>ğ‘¡ over time t = 1, ..., T, where ğ‘œ</em>ğ‘¡ = (ğ‘œ<em>1ğ‘¡, ..., ğ‘œ</em>ğ‘›ğ‘ğ‘¡) is a ğ‘›_ğ‘ dimensional vector of possibly multiple output neurons.</p>
<p>By selecting the identity xf(ğ‘œ<em>ğ‘¡ ) = ğ‘œ</em>ğ‘¡ we can mark preference for the sensitivities or partial derivatives ğ‘¤<em>ğ‘–ğ‘—ğ‘¡=(&quot;âˆ‚&quot; ğ‘œ</em>ğ‘—ğ‘¡)/(&quot;âˆ‚&quot; ğ‘¥<em>ğ‘–ğ‘¡ ), ğ‘– = 1, â€¦, ğ‘›, ğ‘— = 1, â€¦, ğ‘›</em>ğ‘, for each explanatory variable ğ‘¥_ğ‘–ğ‘¡  of the net.</p>
<p>In order to complete the â€™explanationâ€™ derived from the identity one can add a synthetic intercept to each output neuron ğ‘œ_ğ‘—ğ‘¡ defined according to:</p>
<p>ğ‘<em>ğ‘—ğ‘¡â‰”ğ‘œ</em>ğ‘—ğ‘¡âˆ’âˆ‘<em>(ğ‘–=1)^ğ‘›â–’ã€–ğ‘¤</em>ğ‘–ğ‘—ğ‘¡ ğ‘¥_ğ‘–ğ‘¡ ã€—</p>
<p>For each output neuron ğ‘œ<em>ğ‘—ğ‘¡,  the resulting derivatives or â€™explanationsâ€™ ğ‘</em>ğ‘¡, ğ‘¤<em>1ğ‘¡, ğ‘¤</em>(2ğ‘¡ )â€¦ğ‘¤_ğ‘ğ‘¡ generate a new data-flow which is referred to as Linear Parameter Data</p>
<p>The LPD is a matrix of dimension T âˆ— (n + 1), irrespective of the complexity of the neural net, with tâˆ’th row denoted byã€– ğ¿ğ‘ƒğ·ã€—<em>ğ‘¡â‰”(ğ‘</em>ğ‘¡, ğ‘¤<em>1ğ‘¡, ğ‘¤</em>(2ğ‘¡ )â€¦ğ‘¤_ğ‘ğ‘¡)</p>
<p>The LPD can be interpreted in terms of exact replication of the net by a linear model at each time point t and the natural time-ordering of LPDjt subsequently allows to examine changes of the linear replication as a function of time.</p>
<p>We are then in a position to assign a meaning to the neural net, at each time point t = 1, ..., T, and to monitor non-linearities of the net or, by extension, possible non-stationarities of the data.</p>
